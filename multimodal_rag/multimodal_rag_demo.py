#!/usr/bin/env python3
"""
Multimodal RAG - –¢–µ–∫—Å—Ç + –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è
====================================
–î–µ–º–æ–Ω—Å—Ç—Ä—É—î —Ä–æ–±–æ—Ç—É –∑ —Ç–µ–∫—Å—Ç–æ–º —Ç–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º–∏:
- CLIP embeddings –¥–ª—è text —Ç–∞ images
- ChromaDB –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è multimodal embeddings
- –ü–æ—à—É–∫ –ø–æ —Ç–µ–∫—Å—Ç—É –∑–Ω–∞—Ö–æ–¥–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
- –ü–æ—à—É–∫ –ø–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—é –∑–Ω–∞—Ö–æ–¥–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏–π —Ç–µ–∫—Å—Ç

–Ü–Ω—Å–ø—ñ—Ä–æ–≤–∞–Ω–æ: https://milvus.io/blog/nano-banana-milvus-turning-hype-into-enterprise-ready-multimodal-rag.md
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î ChromaDB –∑–∞–º—ñ—Å—Ç—å Milvus –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç–∏

Use cases: E-commerce, Medical imaging, Document analysis
"""

import os
from pathlib import Path
from typing import List, Dict, Any
import json
import warnings
import logging

# –ü—Ä–∏—Ö–æ–≤–∞—Ç–∏ warnings –≤—ñ–¥ transformers —Ç–∞ —ñ–Ω—à–∏—Ö –±—ñ–±–ª—ñ–æ—Ç–µ–∫
warnings.filterwarnings('ignore')
os.environ['TRANSFORMERS_VERBOSITY'] = 'error'

# –ó–º–µ–Ω—à–∏—Ç–∏ verbosity –¥–ª—è transformers logging
logging.getLogger('transformers').setLevel(logging.ERROR)

try:
    import chromadb
    from chromadb.config import Settings
except ImportError:
    print("ChromaDB –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ. –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å: pip install chromadb")
    exit(1)

try:
    from sentence_transformers import SentenceTransformer
    import torch
except ImportError:
    print("sentence-transformers –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ. –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å: pip install sentence-transformers torch")
    exit(1)

try:
    from PIL import Image
except ImportError:
    print("Pillow –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ. –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å: pip install Pillow")
    exit(1)


class MultimodalRAG:
    """
    Multimodal RAG —Å–∏—Å—Ç–µ–º–∞ –∑ ChromaDB

    –û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ:
    - CLIP model –¥–ª—è multimodal embeddings (512D –≤–µ–∫—Ç–æ—Ä—ñ–≤)
      ‚Üí –ö–æ–∂–µ–Ω —Ç–µ–∫—Å—Ç/–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—î—Ç—å—Å—è –≤ –º–∞—Å–∏–≤ –∑ 512 —á–∏—Å–µ–ª
      ‚Üí –¶—ñ —á–∏—Å–ª–∞ –∫–æ–¥—É—é—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è –æ–±'—î–∫—Ç–∞
    - ChromaDB –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ—à—É–∫—É (cosine similarity)
    - –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ text + image queries
    """

    def __init__(self, collection_name: str = "multimodal_collection"):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ Multimodal RAG"""
        print("–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è Multimodal RAG –∑ ChromaDB...")

        # ChromaDB client
        self.client = chromadb.Client(Settings(
            anonymized_telemetry=False,
            allow_reset=True
        ))

        # CLIP model –¥–ª—è multimodal embeddings
        print("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è CLIP model (clip-ViT-B-32)...")
        self.model = SentenceTransformer('clip-ViT-B-32')
        # –û—Ç—Ä–∏–º—É—î–º–æ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å —á–µ—Ä–µ–∑ —Ç–µ—Å—Ç–æ–≤–∏–π embedding
        # –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 512D) = –∫–æ–∂–µ–Ω —Ç–µ–∫—Å—Ç/–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—î—Ç—å—Å—è –≤ –º–∞—Å–∏–≤ –∑ 512 —á–∏—Å–µ–ª
        # –¶—ñ —á–∏—Å–ª–∞ –∫–æ–¥—É—é—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è (—Å–µ–Ω—Å) —Ç–µ–∫—Å—Ç—É/–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        test_embedding = self.model.encode("test")
        self.embedding_dim = len(test_embedding)
        print(f"Model –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ. –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å: {self.embedding_dim}D")

        # –°—Ç–≤–æ—Ä–∏—Ç–∏ –∞–±–æ –æ—Ç—Ä–∏–º–∞—Ç–∏ collection –∑ cosine similarity
        try:
            self.collection = self.client.get_collection(name=collection_name)
            print(f"–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é —ñ—Å–Ω—É—é—á—É collection: {collection_name}")
        except:
            self.collection = self.client.create_collection(
                name=collection_name,
                metadata={"hnsw:space": "cosine"}  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ cosine similarity
            )
            print(f"–°—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤—É collection: {collection_name}")

    def encode_text(self, text: str) -> List[float]:
        """
        –ó–∞–∫–æ–¥—É–≤–∞—Ç–∏ —Ç–µ–∫—Å—Ç –≤ embedding –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é CLIP

        Returns:
            List[float]: –ú–∞—Å–∏–≤ –∑ 512 —á–∏—Å–µ–ª, —è–∫—ñ –∫–æ–¥—É—é—Ç—å –∑–Ω–∞—á–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç—É
        """
        embedding = self.model.encode(text, convert_to_tensor=False)
        return embedding.tolist()

    def encode_image(self, image_path: str) -> List[float]:
        """
        –ó–∞–∫–æ–¥—É–≤–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤ embedding –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é CLIP

        Returns:
            List[float]: –ú–∞—Å–∏–≤ –∑ 512 —á–∏—Å–µ–ª, —è–∫—ñ –∫–æ–¥—É—é—Ç—å –∑–Ω–∞—á–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        """
        try:
            image = Image.open(image_path)
            embedding = self.model.encode(image, convert_to_tensor=False)
            return embedding.tolist()
        except Exception as e:
            print(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è {image_path}: {e}")
            return None

    def add_text_document(self, doc_id: str, text: str, metadata: Dict = None):
        """–î–æ–¥–∞—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤–∏–π –¥–æ–∫—É–º–µ–Ω—Ç"""
        embedding = self.encode_text(text)

        self.collection.add(
            ids=[doc_id],
            embeddings=[embedding],
            documents=[text],
            metadatas=[{
                "type": "text",
                "source": metadata.get("source", "unknown") if metadata else "unknown",
                **(metadata or {})
            }]
        )

    def add_image_document(self, doc_id: str, image_path: str, caption: str = "", metadata: Dict = None):
        """–î–æ–¥–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –æ–ø–∏—Å–æ–º"""
        embedding = self.encode_image(image_path)

        if embedding is None:
            return

        self.collection.add(
            ids=[doc_id],
            embeddings=[embedding],
            documents=[caption or f"Image: {image_path}"],
            metadatas=[{
                "type": "image",
                "image_path": image_path,
                "caption": caption,
                **(metadata or {})
            }]
        )

    def search_by_text(self, query: str, n_results: int = 5) -> Dict[str, Any]:
        """–ü–æ—à—É–∫ –∑–∞ —Ç–µ–∫—Å—Ç–æ–≤–∏–º –∑–∞–ø–∏—Ç–æ–º (–∑–Ω–∞–π–¥–µ —Ç–µ–∫—Å—Ç + –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è)"""
        query_embedding = self.encode_text(query)

        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results
        )

        return self._format_results(results)

    def search_by_image(self, image_path: str, n_results: int = 5) -> Dict[str, Any]:
        """–ü–æ—à—É–∫ –∑–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º (–∑–Ω–∞–π–¥–µ —Å—Ö–æ–∂—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è + —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏–π —Ç–µ–∫—Å—Ç)"""
        query_embedding = self.encode_image(image_path)

        if query_embedding is None:
            return {"error": "Failed to encode image"}

        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results
        )

        return self._format_results(results)

    def _format_results(self, results: Dict) -> Dict[str, Any]:
        """–§–æ—Ä–º–∞—Ç—É–≤–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—à—É–∫—É"""
        formatted = {
            "results": [],
            "count": len(results['ids'][0]) if results['ids'] else 0
        }

        if not results['ids']:
            return formatted

        for i, doc_id in enumerate(results['ids'][0]):
            # –î–ª—è cosine distance: similarity = 1 - distance
            # Cosine distance –≤—ñ–¥ 0 (—ñ–¥–µ–Ω—Ç–∏—á–Ω—ñ) –¥–æ 2 (–ø—Ä–æ—Ç–∏–ª–µ–∂–Ω—ñ)
            # Similarity –≤—ñ–¥ 1 (—ñ–¥–µ–Ω—Ç–∏—á–Ω—ñ) –¥–æ -1 (–ø—Ä–æ—Ç–∏–ª–µ–∂–Ω—ñ)
            cosine_distance = results['distances'][0][i]
            similarity = 1 - cosine_distance

            result = {
                "id": doc_id,
                "score": similarity,  # Cosine similarity –≤—ñ–¥ -1 –¥–æ 1
                "type": results['metadatas'][0][i].get('type', 'unknown'),
                "content": results['documents'][0][i],
                "metadata": results['metadatas'][0][i]
            }
            formatted['results'].append(result)

        return formatted

    def reset_collection(self):
        """–û—á–∏—Å—Ç–∏—Ç–∏ collection"""
        try:
            self.client.delete_collection(name=self.collection.name)
        except:
            pass


def demo_fruit_recognition():
    """
    Demo: –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ñ—Ä—É–∫—Ç—ñ–≤

    –î–µ–º–æ–Ω—Å—Ç—Ä—É—î —è–∫ multimodal RAG –º–æ–∂–µ:
    1. –ó–Ω–∞–π—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ñ—Ä—É–∫—Ç–∞ –∑–∞ —Ç–µ–∫—Å—Ç–æ–≤–∏–º –æ–ø–∏—Å–æ–º
    2. –ó–Ω–∞–π—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ñ—Ä—É–∫—Ç –∑–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º
    """
    print("\n" + "="*70)
    print("MULTIMODAL RAG DEMO: Fruit Recognition")
    print("="*70)

    rag = MultimodalRAG(collection_name="fruits_demo")
    # –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—É collection —è–∫—â–æ —ñ—Å–Ω—É—î
    rag.reset_collection()
    rag = MultimodalRAG(collection_name="fruits_demo")

    # –î–æ–¥–∞—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ñ—Ä—É–∫—Ç–∏
    print("\n–î–æ–¥–∞—î–º–æ —Ç–µ–∫—Å—Ç–æ–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é...")

    fruits_info = {
        "banana_info": {
            "text": "Banana is a yellow tropical fruit, rich in potassium. "
                   "It's curved in shape and has a sweet taste. "
                   "Bananas are great source of energy and vitamins.",
            "source": "fruits_encyclopedia"
        },
        "apple_info": {
            "text": "Apple is a round fruit that comes in red, green, or yellow colors. "
                   "Apples are crunchy and slightly sweet or tart. "
                   "They contain fiber and vitamin C.",
            "source": "fruits_encyclopedia"
        },
        "orange_info": {
            "text": "Orange is a citrus fruit with orange color. "
                   "It's round and has a thick peel. "
                   "Oranges are rich in vitamin C and have juicy, sweet-tart flesh.",
            "source": "fruits_encyclopedia"
        },
        "grapes_info": {
            "text": "A sweet and juicy fruit that grows in clusters on vines. Grapes are often eaten fresh, dried as raisins, or used to make wine and juice. "
                "They come in various colors, including green, red, and purple.",
            "source": "fruits_encyclopedia"
        },
        "strawberry_info": {
            "text": "A bright red, heart-shaped fruit with a sweet and slightly tart flavor. "
                   "Strawberries are enjoyed fresh, in desserts, jams, and smoothies, and are known for their vibrant color and aromatic scent.",
            "source": "fruits_encyclopedia"
        },
        "cherry_info": {
            "text": "A small, round stone fruit with smooth, shiny skin and a single hard pit inside. "
                   "Cherries range in flavor from sweet to tart and are popular for eating fresh, as well as in pies, sauces, and beverages.",
            "source": "fruits_encyclopedia"
        }
    }

    for doc_id, info in fruits_info.items():
        rag.add_text_document(doc_id, info["text"], {"source": info["source"]})
        print(f"  –î–æ–¥–∞–Ω–æ: {doc_id}")

    # –î–æ–¥–∞—î–º–æ —Å–ø—Ä–∞–≤–∂–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ñ—Ä—É–∫—Ç—ñ–≤
    print("\n–î–æ–¥–∞—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ñ—Ä—É–∫—Ç—ñ–≤...")

    # –®–ª—è—Ö –¥–æ –∑–æ–±—Ä–∞–∂–µ–Ω—å
    from pathlib import Path
    script_dir = Path(__file__).parent
    images_dir = script_dir / "images"

    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —ñ—Å–Ω—É—é—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
    image_files = {
        "banana_img": {
            "path": images_dir / "banana.jpg",
            "caption": "A yellow curved banana fruit"
        },
        "apple_img": {
            "path": images_dir / "apple.jpg",
            "caption": "A red round apple fruit"
        },
        "orange_img": {
            "path": images_dir / "orange.jpg",
            "caption": "An orange citrus fruit"
        },
        "grapes_img": {
            "path": images_dir / "grapes.jpg",
            "caption": "A cluster of grapes"
        },
        "strawberry_img": {
            "path": images_dir / "strawberry.jpg",
            "caption": "A bright red strawberry"
        },
        "cherry_img": {
            "path": images_dir / "cherry.jpg",
            "caption": "A small cherry"
        }
    }

    images_added = 0
    for img_id, img_info in image_files.items():
        if img_info["path"].exists():
            rag.add_image_document(
                img_id,
                str(img_info["path"]),
                caption=img_info["caption"],
                metadata={"type": "image", "fruit": img_id.replace("_img", "")}
            )
            print(f"  –î–æ–¥–∞–Ω–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {img_id}")
            images_added += 1
        else:
            print(f"  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {img_id} (—Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ)")

    # –í–∏–∫–æ–Ω—É—î–º–æ –ø–æ—à—É–∫
    print("\n" + "="*70)
    print("–¢–ï–°–¢–£–í–ê–ù–ù–Ø MULTIMODAL SEARCH")
    print("="*70)

    test_queries = [
        "yellow tropical fruit rich in potassium",
        "round citrus fruit with vitamin C",
        "healthy fruit for breakfast",
        "small red fruit with a sweet and slightly tart flavor",
        "small round stone fruit with smooth, shiny skin and a single hard pit inside",
        "sweet and juicy fruit that grows in clusters on vines"
    ]

    all_results = {
        "demo": "Fruit Recognition",
        "embedding_dim": rag.embedding_dim,
        "model": "clip-ViT-B-32",
        "total_documents": len(fruits_info) + images_added,
        "queries": []
    }

    for i, query in enumerate(test_queries, 1):
        print(f"\n–ó–∞–ø–∏—Ç {i}: {query}")
        results = rag.search_by_text(query, n_results=3)

        query_result = {
            "query": query,
            "results_count": results['count'],
            "top_results": []
        }

        for j, result in enumerate(results['results'], 1):
            print(f"  {j}. {result['id']} | Score: {result['score']:.3f} | Type: {result['type']}")
            query_result['top_results'].append({
                "id": result['id'],
                "score": result['score'],
                "type": result['type']
            })

        all_results["queries"].append(query_result)

    # –î–æ–¥–∞—Ç–∫–æ–≤–æ: –ø–æ—à—É–∫ –∑–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º (—è–∫—â–æ —î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è)
    if images_added > 0:
        print("\n" + "="*70)
        print("–¢–ï–°–¢–£–í–ê–ù–ù–Ø IMAGE-TO-TEXT SEARCH")
        print("="*70)

        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –æ–¥–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –ø–æ—à—É–∫—É —Å—Ö–æ–∂–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
        test_image = images_dir / "banana.jpg"
        if test_image.exists():
            print(f"\n–ü–æ—à—É–∫ –∑–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º: banana.jpg")
            results = rag.search_by_image(str(test_image), n_results=3)

            query_result = {
                "query_type": "image",
                "query_image": "banana.jpg",
                "results_count": results['count'],
                "top_results": []
            }

            for j, result in enumerate(results['results'], 1):
                print(f"  {j}. {result['id']} | Score: {result['score']:.3f} | Type: {result['type']}")
                query_result['top_results'].append({
                    "id": result['id'],
                    "score": result['score'],
                    "type": result['type']
                })

            all_results["queries"].append(query_result)

    print("\n" + "="*70)

    # –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π —Ä–µ–∂–∏–º: –≤–≤–µ–¥—ñ—Ç—å –Ω–∞–∑–≤—É –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —ñ –æ—Ç—Ä–∏–º–∞—î—Ç–µ —Ç–µ, —â–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ RAG
    try:
        print("\n–Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π —Ä–µ–∂–∏–º: –≤–≤–µ–¥—ñ—Ç—å –Ω–∞–∑–≤—É –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –ø–∞–ø–∫–∏ 'images' (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 'banana.jpg' –∞–±–æ 'banana'). –í–≤–µ–¥—ñ—Ç—å 'stop' —â–æ–± –∑–∞–≤–µ—Ä—à–∏—Ç–∏.")

        # –ú–∞–ø—ñ–Ω–≥ –Ω–∞–∑–≤–∏ —Ñ–∞–π–ª—É/–±–∞–∑–∏ –¥–æ id –¥–æ–∫—É–º–µ–Ω—Ç–∞
        filename_to_id = {}
        for img_id, info in image_files.items():
            fname = info["path"].name.lower()
            base = info["path"].stem.lower()
            filename_to_id[fname] = img_id
            filename_to_id[base] = img_id

        while True:
            user_inp = input("\nüóùÔ∏è –í–≤–µ–¥—ñ—Ç—å –Ω–∞–∑–≤—É –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∞–±–æ 'stop': ").strip().lower()
            if user_inp in ("stop", "exit", "quit"):
                break
            if not user_inp:
                continue

            key = user_inp
            if key not in filename_to_id and not key.endswith(".jpg") and f"{key}.jpg" in filename_to_id:
                key = f"{key}.jpg"

            if key not in filename_to_id:
                available = ", ".join(sorted({p['path'].name for p in image_files.values() if p['path'].exists()}))
                print(f"  ‚ö†Ô∏è –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –î–æ—Å—Ç—É–ø–Ω—ñ: {available}")
                continue

            found_id = filename_to_id[key]

            # –°–ø—Ä–æ–±—É–≤–∞—Ç–∏ –æ—Ç—Ä–∏–º–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –¥–∞–Ω—ñ –±–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ –∑ ChromaDB
            stored = None
            try:
                stored = rag.collection.get(ids=[found_id])
            except Exception:
                stored = None

            print("\n‚Äî –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è:", found_id)
            if stored and stored.get('ids'):
                idx = 0
                print(f"  ID: {stored['ids'][idx]}")
                meta = stored['metadatas'][idx] or {}
                print(f"  Type: {meta.get('type')}")
                print(f"  Image path: {meta.get('image_path')}")
                print(f"  Caption: {meta.get('caption')}")
                if 'fruit' in meta:
                    print(f"  Fruit tag: {meta.get('fruit')}")
                # –ü–æ–≤–Ω—ñ –º–µ—Ç–∞–¥–∞–Ω—ñ
                try:
                    print("  Metadata:")
                    print("   " + json.dumps(meta, ensure_ascii=False, indent=2).replace("\n", "\n   "))
                except Exception:
                    print(f"  Metadata (raw): {meta}")
                # –î–æ–∫—É–º–µ–Ω—Ç/–æ–ø–∏—Å
                print(f"  Document: {stored['documents'][idx]}")
                # –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å embedding (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∞)
                emb_dim = None
                if stored.get('embeddings') and stored['embeddings'][idx] is not None:
                    try:
                        emb_dim = len(stored['embeddings'][idx])
                    except Exception:
                        emb_dim = None
                if emb_dim:
                    print(f"  Embedding dim: {emb_dim}")
            else:
                print("  ‚ö†Ô∏è –ó–∞–ø–∏—Å –¥–ª—è —Ü—å–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ RAG.")

    except EOFError:
        pass

    print("\n" + "="*70)

    return all_results


def demo_product_search():
    """
    Demo: –ü–æ—à—É–∫ –ø—Ä–æ–¥—É–∫—Ç—ñ–≤ (e-commerce use case)

    –ü–æ–∫–∞–∑—É—î —è–∫ multimodal RAG –º–æ–∂–µ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏ –≤ e-commerce:
    - –ü–æ—à—É–∫ —Ç–æ–≤–∞—Ä—É –∑–∞ —Ç–µ–∫—Å—Ç–æ–≤–∏–º –æ–ø–∏—Å–æ–º
    - –ü–æ—à—É–∫ —Å—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä—ñ–≤
    """
    print("\n" + "="*70)
    print("MULTIMODAL RAG DEMO: E-Commerce Product Search")
    print("="*70)

    rag = MultimodalRAG(collection_name="products_demo")
    # –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—É collection —è–∫—â–æ —ñ—Å–Ω—É—î
    rag.reset_collection()
    rag = MultimodalRAG(collection_name="products_demo")

    # –î–æ–¥–∞—Ç–∏ –ø—Ä–æ–¥—É–∫—Ç–∏
    print("\n–î–æ–¥–∞—î–º–æ –ø—Ä–æ–¥—É–∫—Ç–∏...")

    products = {
        "laptop_001": {
            "text": "MacBook Pro 16-inch with M4 chip. Silver aluminum body. "
                   "High-performance laptop for professionals. 16GB RAM, 512GB SSD.",
            "metadata": {"category": "electronics", "price": 2499, "brand": "Apple"}
        },
        "laptop_002": {
            "text": "Dell XPS 15 laptop with Intel i7 processor. "
                   "Black carbon fiber design. 32GB RAM, 1TB SSD. Perfect for developers.",
            "metadata": {"category": "electronics", "price": 1999, "brand": "Dell"}
        },
        "chair_001": {
            "text": "Ergonomic office chair with lumbar support. "
                   "Black mesh back, adjustable height. Comfortable for long work sessions.",
            "metadata": {"category": "furniture", "price": 299, "brand": "Herman Miller"}
        }
    }

    for prod_id, info in products.items():
        rag.add_text_document(prod_id, info["text"], info["metadata"])
        print(f"  –î–æ–¥–∞–Ω–æ: {prod_id}")

    # –ü–æ—à—É–∫–æ–≤—ñ –∑–∞–ø–∏—Ç–∏
    print("\n" + "="*70)
    print("–¢–ï–°–¢–£–í–ê–ù–ù–Ø PRODUCT SEARCH")
    print("="*70)

    test_queries = [
        "powerful laptop for software development",
        "Apple professional computer",
        "comfortable chair for home office"
    ]

    all_results = {
        "demo": "E-Commerce Product Search",
        "embedding_dim": rag.embedding_dim,
        "model": "clip-ViT-B-32",
        "total_products": len(products),
        "queries": []
    }

    for i, query in enumerate(test_queries, 1):
        print(f"\n–ó–∞–ø–∏—Ç {i}: {query}")
        results = rag.search_by_text(query, n_results=3)

        query_result = {
            "query": query,
            "results_count": results['count'],
            "top_results": []
        }

        for j, result in enumerate(results['results'], 1):
            print(f"  {j}. {result['id']} | Score: {result['score']:.3f}")
            query_result['top_results'].append({
                "id": result['id'],
                "score": result['score'],
                "metadata": result['metadata']
            })

        all_results["queries"].append(query_result)

    print("\n" + "="*70)

    return all_results


def run_multimodal_rag_demo():
    """–ó–∞–ø—É—Å–∫–∞—î –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—é Multimodal RAG"""
    print("="*70)
    print("MULTIMODAL RAG –î–ï–ú–û–ù–°–¢–†–ê–¶–Ü–Ø")
    print("="*70)

    print("\n–ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è:")
    print("  –ú–æ–¥–µ–ª—å: CLIP (clip-ViT-B-32)")
    print("  –í–µ–∫—Ç–æ—Ä–Ω–∞ –ë–î: ChromaDB")
    print("  –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å embeddings: 512D")
    print("    (–∫–æ–∂–µ–Ω —Ç–µ–∫—Å—Ç/–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è ‚Üí –º–∞—Å–∏–≤ –∑ 512 —á–∏—Å–µ–ª, —è–∫—ñ –∫–æ–¥—É—é—Ç—å –∑–Ω–∞—á–µ–Ω–Ω—è)")
    print("  –¢–µ—Ö–Ω—ñ–∫–∏: Multimodal embeddings, Cross-modal search")

    try:
        # Demo 1: Fruit Recognition
        fruits_results = demo_fruit_recognition()

        # Demo 2: E-Commerce Product Search
        products_results = demo_product_search()

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        all_results = {
            "system_name": "Multimodal RAG",
            "embedding_model": "clip-ViT-B-32",
            "embedding_dim": 512,
            "vector_db": "ChromaDB",
            "demos": [
                fruits_results,
                products_results
            ]
        }

        results_dir = Path("results")
        results_dir.mkdir(exist_ok=True)

        with open(results_dir / "multimodal_rag_results_clean.json", "w", encoding="utf-8") as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)

        print("\n–ü–Ü–î–°–£–ú–û–ö")
        print("="*70)
        print(f"–í—Å—å–æ–≥–æ demo: {len(all_results['demos'])}")
        print(f"–ú–æ–¥–µ–ª—å: {all_results['embedding_model']}")
        print(f"–†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å: {all_results['embedding_dim']}D")
        print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: results/multimodal_rag_results_clean.json")
        print("="*70)

    except KeyboardInterrupt:
        print("\n\nDemo –ø–µ—Ä–µ—Ä–≤–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º")
    except Exception as e:
        print(f"\n–ü–æ–º–∏–ª–∫–∞: {e}")
        import traceback
        traceback.print_exc()

    print("\n–ö–õ–Æ–ß–û–í–Ü –í–ò–°–ù–û–í–ö–ò")
    print("="*70)
    print("1. Multimodal RAG –æ–±'—î–¥–Ω—É—î TEXT + IMAGES –≤ –æ–¥–Ω–æ–º—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ")
    print("2. CLIP model –¥–æ–∑–≤–æ–ª—è—î:")
    print("   - –ó–Ω–∞–π—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–∞ —Ç–µ–∫—Å—Ç–æ–≤–∏–º –æ–ø–∏—Å–æ–º")
    print("   - –ó–Ω–∞–π—Ç–∏ —Ç–µ–∫—Å—Ç –∑–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º")
    print("   - –ó–Ω–∞–π—Ç–∏ —Å—Ö–æ–∂—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è")
    print("3. ChromaDB —Å–ø—Ä–æ—â—É—î —Ä–æ–±–æ—Ç—É –∑ multimodal embeddings")
    print("4. Use cases: E-commerce, Medical imaging, Document analysis")
    print("="*70)


if __name__ == "__main__":
    run_multimodal_rag_demo()
